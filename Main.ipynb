{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b35323e",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirement.txt\n",
    "print('Successfully loaded requirements')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422d89d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "import pyaudio\n",
    "import wave\n",
    "import warnings\n",
    "import python_speech_features as mfcc\n",
    "import io\n",
    "import ffmpeg\n",
    "import gtts\n",
    "import os.path\n",
    "import shutil\n",
    "import serial.tools.list_ports\n",
    "import platform\n",
    "\n",
    "from IPython.display import display, Javascript, Audio, clear_output\n",
    "from base64 import b64decode\n",
    "from numpy import genfromtxt\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import mixture\n",
    "from sklearn.mixture import GMM \n",
    "from sklearn import preprocessing\n",
    "from IPython.display import HTML, Audio\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "from os import path \n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from js2py import eval_js\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.nan)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Imports successfully loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b7d67",
   "metadata": {},
   "source": [
    "# Connecting Serial IO\n",
    "* Links arduino board according to port number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ae067",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = serial.Serial()\n",
    "ser.baudrate = '9600'\n",
    "ser.port = 'COM3'\n",
    "ser.open()\n",
    "\n",
    "print(\"Access granted..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa159f5",
   "metadata": {},
   "source": [
    "# Text to Audio Function \n",
    "* Converts text strings to voice outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4aa51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text2Speech(text):\n",
    "  new_sound = str(text)\n",
    "  tts = gtts.gTTS(new_sound)\n",
    "  new_sound_file = str('./Text2Speech/new_sound.mp3')\n",
    "  tts.save(new_sound_file)\n",
    "  \n",
    "  return Audio(new_sound_file, autoplay = True)\n",
    "  \n",
    "print('Loaded...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd426f",
   "metadata": {},
   "source": [
    "# Audio Processing Functions\n",
    "* Extracts 40 dimensional MFCC and delta MFCC features as a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate and returns the delta of given feature vector matrix\n",
    "def calculate_delta(array):\n",
    "    rows,cols = array.shape\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first = 0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows -1:\n",
    "                second = rows -1\n",
    "            else:\n",
    "                second = i+j\n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas\n",
    "\n",
    "#convert audio to mfcc features\n",
    "def extract_features(audio,rate):    \n",
    "    mfcc_feat = mfcc.mfcc(audio,rate, 0.025, 0.01,20,appendEnergy = True, nfft=1103)\n",
    "    mfcc_feat = preprocessing.scale(mfcc_feat)\n",
    "    delta = calculate_delta(mfcc_feat)\n",
    "\n",
    "    #combining both mfcc features and delta\n",
    "    combined = np.hstack((mfcc_feat,delta)) \n",
    "    return combined\n",
    "\n",
    "print('Loaded...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a897857",
   "metadata": {},
   "source": [
    "# Facial Encoding\n",
    "The model provides output as 128 dim encoding vector for the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provides 128 dim embeddings for face\n",
    "def img_to_encoding(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #converting img format to channel first\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "\n",
    "    x_train = np.array([img])\n",
    "\n",
    "    #facial embedding from trained model\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding\n",
    "\n",
    "print(\"Loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f82c1",
   "metadata": {},
   "source": [
    "# Triplet Loss\n",
    "Two encodings are compared and if they are similar then two images are of the same person otherwise they are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a371319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    # triplet loss formula \n",
    "    pos_dist = tf.reduce_sum( tf.square(tf.subtract(y_pred[0], y_pred[1])) )\n",
    "    neg_dist = tf.reduce_sum( tf.square(tf.subtract(y_pred[0], y_pred[2])) )\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    loss = tf.maximum(basic_loss, 0.0)\n",
    "   \n",
    "    return loss\n",
    "\n",
    "# load the model\n",
    "# where is facenet_model/model.h5 stored? for colab you'll need to upload this file to your GDrive and then use the mount function: https://colab.research.google.com/notebooks/io.ipynb\n",
    "# model = load_model('/content/gdrive/MyDrive/ColabNotebooks/facenet_model/model.h5', custom_objects={'triplet_loss': triplet_loss})\n",
    "\n",
    "model = load_model('./facenet_model/model.h5', custom_objects={'triplet_loss': triplet_loss}, compile = False)\n",
    "\n",
    "print(\"Loaded..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05538eba",
   "metadata": {},
   "source": [
    "# Delete User Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1414f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_user(name):\n",
    "    \n",
    "    with open(\"./face_database/embeddings.pickle\", \"rb\") as database:\n",
    "        db = pickle.load(database)\n",
    "        user = db.pop(name, None)\n",
    "    \n",
    "        if user is not None:\n",
    "            print('User ' + name + ' deleted successfully')\n",
    "            # save the database\n",
    "            with open('./face_database/embeddings.pickle', 'wb') as database:\n",
    "                    pickle.dump(db, database, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            # remove the speaker wav files and gmm model\n",
    "            [os.remove(path) for path in glob.glob('./voice_database/' + name + '/*')]\n",
    "            os.removedirs('./voice_database/' + name)\n",
    "            os.remove('./gmm_models/' + name + '.gmm')\n",
    "            \n",
    "            delete = str( name + ' your data has been deleted')\n",
    "            return delete\n",
    "        \n",
    "        else:\n",
    "            print('No such user !!')\n",
    "            delete = 'User is not registered, please enter an existing user'\n",
    "            return delete\n",
    "        \n",
    "print('Successfully loaded function...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8470ad1",
   "metadata": {},
   "source": [
    "# Add User Function\n",
    "* Facial data    \n",
    "    * Face detection \n",
    "    * Extracts facial embeddings from photo and stores as pickle data\n",
    "* Voice data\n",
    "    * User repeats password 3 times\n",
    "    * Extracts MFCC features\n",
    "    * Concatenates all 3 voice samples as features\n",
    "    * Passes to GMM model and saves as .gmm file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275baf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data i/o you'll need to create the relevant folders on your GDrive and then use the mount function: https://colab.research.google.com/notebooks/io.ipynb\n",
    "def add_user(name):\n",
    "    \n",
    "    with open('./face_database/embeddings.pickle', 'rb') as database:\n",
    "        db = pickle.load(database)   \n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 640)\n",
    "    cap.set(4, 480)\n",
    "    \n",
    "    #detecting only frontal face using haarcascade\n",
    "    face_cascade = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    i = 3\n",
    "    face_found = False\n",
    "    \n",
    "    while True:            \n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "            \n",
    "        #time.sleep(1.0)\n",
    "        cv2.putText(frame, 'Keep Your Face infront of Camera', (100, 200),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, 'Starting', (260, 270), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, str(i), (290, 330), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1.3, (255, 255, 255), 3)\n",
    "        \n",
    "        i-=1\n",
    "                   \n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(1000) \n",
    "                \n",
    "        if i < 0:\n",
    "            break\n",
    "            \n",
    "    start_time = time.time()        \n",
    "\n",
    "    ## Face recognition \n",
    "    while True:\n",
    "        curr_time = time.time()\n",
    "        \n",
    "        _,frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "        # if (frame is not None):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        face = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        if len(face) == 1:\n",
    "            for(x, y, w, h) in face:\n",
    "                roi = frame[y-10:y+h+10, x-10:x+w+10]\n",
    "\n",
    "                fh, fw = roi.shape[:2]\n",
    "\n",
    "                #make sure the face roi is of required height and width\n",
    "                if fh < 20 and fw < 20:\n",
    "                    continue\n",
    "\n",
    "                face_found = True\n",
    "                #cv2.imwrite(img_path, roi)\n",
    "\n",
    "                cv2.rectangle(frame, (x-10,y-10), (x+w+10, y+h+10), (255, 200, 200), 2)\n",
    "\n",
    "         \n",
    "        if curr_time - start_time >= 3:\n",
    "            break\n",
    "            \n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(1)\n",
    "            \n",
    "    cap.release()        \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    if face_found:\n",
    "        img = cv2.resize(roi, (96, 96))\n",
    "\n",
    "        db[name] = img_to_encoding(img)\n",
    "\n",
    "        with open('./face_database/embeddings.pickle', \"wb\") as database:\n",
    "            pickle.dump(db, database, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    elif len(face) > 1:\n",
    "        print(\"More than one faces found. Try again...\")\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        print('There was no face found in the frame. Try again...')\n",
    "        return\n",
    "      \n",
    "    clear_output(wait=True) \n",
    "    \n",
    "#     Voice authentication\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 3\n",
    "    \n",
    "    source = \"./voice_database/\" + name\n",
    "    \n",
    "   \n",
    "    os.mkdir(source)\n",
    "\n",
    "    for i in range(3):\n",
    "        audio = pyaudio.PyAudio()\n",
    "\n",
    "        if i == 0:\n",
    "            j = 3\n",
    "            while j>=0:\n",
    "                time.sleep(1.0)\n",
    "                print(\"The password is Open Sesame\")\n",
    "                print(\"Say it in {} seconds\".format(j))\n",
    "                clear_output(wait=True)\n",
    "\n",
    "                j-=1\n",
    "\n",
    "        elif i ==1:\n",
    "            print(\"Say it one more time\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        else:\n",
    "            print(\"Say it one last time\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        # start Recording\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "        print(\"recording...\")\n",
    "        frames = []\n",
    "\n",
    "        for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "        # stop Recording\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        \n",
    "        # saving wav file of speaker\n",
    "        waveFile = wave.open(source + '/' + str((i+1)) + '.wav', 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "        print(\"Done\")\n",
    "\n",
    "    dest =  \"./gmm_models/\"\n",
    "    count = 1\n",
    "\n",
    "    for path in os.listdir(source):\n",
    "        path = os.path.join(source, path)\n",
    "\n",
    "        features = np.array([])\n",
    "        \n",
    "        # reading audio files of speaker\n",
    "        (sr, audio) = read(path)\n",
    "        \n",
    "        # extract 40 dimensional MFCC & delta MFCC features\n",
    "        vector   = extract_features(audio,sr)\n",
    "\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "            \n",
    "        # when features of 3 files of speaker are concatenated, then do model training\n",
    "        if count == 3:    \n",
    "            gmm = GMM(n_components = 16, n_iter = 200, covariance_type='diag',n_init = 3)\n",
    "#             gmm = mixture.GaussianMixture(n_components = 16, n_iter = 200, covariance_type='diag',n_init = 3)\n",
    "\n",
    "            gmm.fit(features)\n",
    "\n",
    "            # saving the trained gaussian model\n",
    "            pickle.dump(gmm, open(dest + name + '.gmm', 'wb'))\n",
    "            print(name + ' is successfully registered in the database.') \n",
    "            \n",
    "            features = np.asarray(())\n",
    "            count = 0\n",
    "        count = count + 1\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     add_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc045866",
   "metadata": {},
   "source": [
    "# Recognise Function\n",
    "* Voice recognition based on GMM model, comparing extracted MFCC features\n",
    "* Face recognition based on Siamese Neural Network model, comparing extracted embeddings with user embeddings in database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_functions import *\n",
    "\n",
    "def recognize():\n",
    "    # Voice Authentication\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 4\n",
    "    FILENAME = \"./test.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "    \n",
    "    j = 3\n",
    "    while j>=0:\n",
    "        time.sleep(1.0)\n",
    "        print(\"What is password?\")\n",
    "        print(\"Say it in {} seconds\".format(j))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        j-=1\n",
    "   \n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"finished recording\")\n",
    "\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # saving wav file \n",
    "    waveFile = wave.open(FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "    modelpath = \"./gmm_models/\"\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in \n",
    "                os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "\n",
    "    speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname \n",
    "                in gmm_files]\n",
    "  \n",
    "    if len(models) == 0:\n",
    "        print(\"No Users in the Database!\")\n",
    "        return\n",
    "        \n",
    "    #read test file\n",
    "    sr,audio = read(FILENAME)\n",
    "\n",
    "    # extract mfcc features\n",
    "    vector = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "\n",
    "    #checking with each model one by one\n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i]         \n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    pred = np.argmax(log_likelihood)\n",
    "    identity = speakers[pred]\n",
    "   \n",
    "    # if voice not recognized than terminate the process\n",
    "    if identity == 'unknown':\n",
    "            print(\"Not Recognized! Try again...\")\n",
    "            response = \"Voice not recognized! Please try again\"\n",
    "            code = 0\n",
    "            return response, code\n",
    "    \n",
    "    print( \"User: \", identity)\n",
    "\n",
    "    # face recognition\n",
    "    print(\"Keep Your face infront of the camera\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 640)\n",
    "    cap.set(4, 480)\n",
    "\n",
    "    cascade = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    #loading the database \n",
    "    database = pickle.load(open('./face_database/embeddings.pickle', \"rb\"))\n",
    "    \n",
    "#     time.sleep(1.0)\n",
    "    i = 3\n",
    "    while True:            \n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "            \n",
    "        #time.sleep(1.0)\n",
    "        cv2.putText(frame, 'Keep Your Face infront of Camera', (100, 200),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, 'Commencing Facial Recognition Sequence', (80, 270), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, str(i), (290, 330), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1.3, (255, 255, 255), 3)\n",
    "        \n",
    "        i-=1\n",
    "                   \n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(1000) \n",
    "                \n",
    "        if i < 0:\n",
    "            break\n",
    "            \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        curr_time = time.time()\n",
    "            \n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        face = cascade.detectMultiScale(gray, 1.3, 5)\n",
    "         \n",
    "        name = 'unknown'\n",
    "        \n",
    "        \n",
    "        if len(face) == 1:\n",
    "\n",
    "            for (x, y, w, h) in face:\n",
    "                roi = frame[y-10:y+h+10, x-10:x+w+10]\n",
    "            \n",
    "                fh, fw = roi.shape[:2]\n",
    "                min_dist = 100\n",
    "                \n",
    "                #make sure the face is of required height and width\n",
    "                if fh < 20 and fh < 20:\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                #resizing image as required by the model\n",
    "                img = cv2.resize(roi, (96, 96))\n",
    "\n",
    "                #128 d encodings from pre-trained model\n",
    "                encoding = img_to_encoding(img)\n",
    "                \n",
    "                # loop over all the recorded encodings in database \n",
    "                for knownName in database:\n",
    "                    # find the similarity between the input encodings and recorded encodings in database using L2 norm\n",
    "                    dist = np.linalg.norm(np.subtract(database[knownName], encoding) )\n",
    "                    # check if minimum distance or not\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        name = knownName\n",
    "\n",
    "            # if min dist is less then threshold value and face and voice matched than unlock the door\n",
    "            if min_dist <= 0.7 and name == identity:\n",
    "                entry = str('Door Unlocked! Welcome ' + name + ', you may enter!')\n",
    "                code = 1\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return entry, code\n",
    "#                 break\n",
    "\n",
    "        #open the cam for 3 seconds\n",
    "        if curr_time - start_time >= 3:\n",
    "            break    \n",
    "\n",
    "#         cv2.waitKey(1)\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(500)\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "   \n",
    "    if len(face) == 0:\n",
    "        response = 'There was no face found in the frame. Please try again..'\n",
    "        code = 0\n",
    "        print(response)\n",
    "        return response, code\n",
    "        \n",
    "    elif len(face) > 1:\n",
    "        response = 'The system is detecting more than one face. Please try again..'\n",
    "        code = 0\n",
    "        print(response)\n",
    "        return response, code\n",
    "        \n",
    "    elif min_dist > 0.7 or name != identity:\n",
    "        response = 'User is not recognised. Entry denied'\n",
    "        code = 0\n",
    "        print(response)\n",
    "        return response, code\n",
    "   \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    response, code = recognize()\n",
    "    \n",
    "Text2Speech(response)\n",
    "# print(code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a874f",
   "metadata": {},
   "source": [
    "# List of registered users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_list():\n",
    "    database = pickle.load(open('./face_database/embeddings.pickle', \"rb\"))\n",
    "    soize = len(database)\n",
    "\n",
    "    \n",
    "    if soize == 0: \n",
    "        print(\"There are no registered users.\")\n",
    "    else:\n",
    "        print(\"List of registered users: \")\n",
    "        i = 1\n",
    "        while (i < soize + 1):\n",
    "          for knownName in database: \n",
    "            name = knownName\n",
    "            print(str(i) + '. ' + name)\n",
    "            i+=1\n",
    "\n",
    "check_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1874af14",
   "metadata": {},
   "source": [
    "# User Registration (1)\n",
    "* Updated UI to allow for dev-only access to user registration/removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authority_check():\n",
    "    user = input('Would you like to register or delete a user? (y/n)')\n",
    "    if user is 'y':\n",
    "        res, code = recognize()\n",
    "        if code == 1: \n",
    "            registration = user_reg()\n",
    "            return registration\n",
    "        else: \n",
    "            prompt = \"Sorry, you do not have the authority.\"\n",
    "            print(prompt)\n",
    "            return prompt\n",
    "\n",
    "authority = authority_check()\n",
    "Text2Speech(authority)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a90c1",
   "metadata": {},
   "source": [
    "# User Registration (2)\n",
    "* Basic UI for registration and removal of users\n",
    "* User selects option to proceed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1306396",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for user interface: \n",
    "## 2 options for users: 1. Register new user \n",
    "##                          Case 1: User does not exist\n",
    "##                          Case 2: User exists, remove option given\n",
    "##                      2. Delete user \n",
    "##------------------------------------------------------------------------------\n",
    "\n",
    "def user_reg():\n",
    "  user = input('Do you want to: 1. Register new user; 2. Delete user : ')\n",
    "  if user is '1':\n",
    "    # Prompt user to enter name to search database\n",
    "    name = input(\"Enter name: \")\n",
    "    user_reg.name = name\n",
    "    if os.path.exists('./face_database/embeddings.pickle'):\n",
    "        with open('./face_database/embeddings.pickle', 'rb') as database:\n",
    "            db = pickle.load(database)   \n",
    "            \n",
    "            if name in db or name == 'unknown':\n",
    "                # print(\"User has been previously registered, would you like to delete it? (y/n): \")\n",
    "                # If user exist, overwrite data \n",
    "                user = input('User has been previously registered, would you like to delete it? (y/n): ')\n",
    "                \n",
    "                if user is 'y':\n",
    "                  delete_file = delete_user(name)\n",
    "                  return delete_file\n",
    "                \n",
    "                elif user is 'n':\n",
    "                  goodbye = str('Well good day')\n",
    "                  print('Well good day then..')\n",
    "                  return goodbye\n",
    "                else: \n",
    "                  excuse = str('Please enter a valid response')\n",
    "                  print('WTF')\n",
    "                  return excuse\n",
    "                          # return\n",
    "            else:\n",
    "                #if database not exists than creating new database\n",
    "                db = {}\n",
    "\n",
    "\n",
    "            face_cascade = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "            user = input('Would you like to be registered? (y/n): ')\n",
    "            if user is 'y':\n",
    "              print('Name saved! Welcome to the system ' + name + '!')\n",
    "              add_user(name)\n",
    "              save_file = str('Hello '+ user_reg.name + ', your biometric data has been saved.')\n",
    "              return save_file\n",
    "\n",
    "            elif user is 'n':\n",
    "              response = str('What are you waiting for then? Good day.')\n",
    "              return response\n",
    "            \n",
    "            else:\n",
    "              response = str('Please enter a valid response!')\n",
    "              print(response)\n",
    "              return response\n",
    "\n",
    "  elif user is '2':\n",
    "    check_list()\n",
    "    print('Enter a user you would like to remove: ')\n",
    "    text = input('')\n",
    "    delete_file = delete_user_OG(text)\n",
    "    return delete_file\n",
    "    \n",
    "  else: \n",
    "    goodbye = str('Please enter a valid response.')\n",
    "    print('Please make a valid selection')\n",
    "    return goodbye\n",
    "\n",
    "registration = user_reg()\n",
    "\n",
    "# print(registration)\n",
    "Text2Speech(registration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6227a0",
   "metadata": {},
   "source": [
    "# PPBAS Sequence Initiator\n",
    "* Acts a function caller, awaits user to approach device\n",
    "* Once user is detected, initiates recognition sequence \n",
    "* If user is verified, unlocks door for 5 seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet demonstrates the overall authentication sequence of PPBAS\n",
    "caller = 0\n",
    "while caller < 1: \n",
    "    if caller == 1:\n",
    "        break\n",
    "    time.sleep(0.2)\n",
    "    ser.reset_input_buffer()\n",
    "    b = ser.readline()\n",
    "    string = b.decode()\n",
    "    \n",
    "    caller = int(string)\n",
    "\n",
    "print(\"User detected! Initiating sequence...\")\n",
    "\n",
    "if caller == 1:\n",
    "    response, code = recognize() \n",
    "    if code is 1: \n",
    "        # Door lock actuated\n",
    "        ser.write(b'1')\n",
    "        \n",
    "Text2Speech(response)\n",
    "print(response)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb155799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
